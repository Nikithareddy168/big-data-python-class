{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an ipython notebook to provide a tutorial showing the steps to perform dimensional reduction using https://www.codementor.io/jadianes/data-science-python-pandas-r-dimensionality-reduction-du1081aka as the basis and a dataset of your choosing :\n",
    "Your tutorial will  include\n",
    "\n",
    "1. a short description of what is the dimensionality of the data and why and how to pick the dimensions for use\n",
    "\n",
    "2, Initial Data setup\n",
    "\n",
    "3. Dimensional reduction process\n",
    "\n",
    "4. Display in graph and plots\n",
    "\n",
    "5. Discussion of the images in the graphs and plots\n",
    "\n",
    "6. Bibliography ( urls and names of pages and authors of used code and descriptions )  Be sure to put in \n",
    "\n",
    "  You should submit your ipython notebook url in your github account or zip your homework9 directory and  submit it.\n",
    "\n",
    "Be sure that if someone downloads your directory the notebook will run as shown.  So any scripts or images used in the notebook\n",
    "\n",
    "are local to the directory of the notebook.  You must have citations and references marked in the text.  You can use http://www.citationmachine.net  to help standardize your references at the end of you document\n",
    "\n",
    "For more credit continue with the cluster analysis of the dimensionally reduced code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dimensional reduction process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Dimesionality reduction is all about discovering non-linear, non-local relationships in data that  are not obvious in the original feature space.  If we reduce some dimension in the data we can visualize it because a projection in 2D/3D space can be plotted easily. Training a model on a dataset with many dimensions usually7 requires vast time and space complexity.  Not all the features that are available in the dataset are relavant to our problem. If we reduce the dimensions we can reduce the unnecessary parts of the data. So, once we have a small data we can easily apply the algorithms on them.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimesionaly reduction can be divided into two different features. \n",
    "1. Feature Selection  :  Finding the most relevant features of a problem is feature selection\n",
    "2. feature Extraction : Finding new features after transforming the data  from a high dimensional space to lower dimensional space possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to use the PCA(Personal component analysis) which is one of the Feature extraction algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, I imported the data from sklearn and prepared a dataframe for performing analysis on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07451</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.08243</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "5        12.45         15.70           82.57      477.1          0.12780   \n",
       "6        18.25         19.98          119.60     1040.0          0.09463   \n",
       "7        13.71         20.83           90.20      577.9          0.11890   \n",
       "8        13.00         21.82           87.50      519.8          0.12730   \n",
       "9        12.46         24.04           83.97      475.9          0.11860   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760         0.30010              0.14710         0.2419   \n",
       "1           0.07864         0.08690              0.07017         0.1812   \n",
       "2           0.15990         0.19740              0.12790         0.2069   \n",
       "3           0.28390         0.24140              0.10520         0.2597   \n",
       "4           0.13280         0.19800              0.10430         0.1809   \n",
       "5           0.17000         0.15780              0.08089         0.2087   \n",
       "6           0.10900         0.11270              0.07400         0.1794   \n",
       "7           0.16450         0.09366              0.05985         0.2196   \n",
       "8           0.19320         0.18590              0.09353         0.2350   \n",
       "9           0.23960         0.22730              0.08543         0.2030   \n",
       "\n",
       "   mean fractal dimension           ...             worst radius  \\\n",
       "0                 0.07871           ...                    25.38   \n",
       "1                 0.05667           ...                    24.99   \n",
       "2                 0.05999           ...                    23.57   \n",
       "3                 0.09744           ...                    14.91   \n",
       "4                 0.05883           ...                    22.54   \n",
       "5                 0.07613           ...                    15.47   \n",
       "6                 0.05742           ...                    22.88   \n",
       "7                 0.07451           ...                    17.06   \n",
       "8                 0.07389           ...                    15.49   \n",
       "9                 0.08243           ...                    15.09   \n",
       "\n",
       "   worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0          17.33           184.60      2019.0            0.1622   \n",
       "1          23.41           158.80      1956.0            0.1238   \n",
       "2          25.53           152.50      1709.0            0.1444   \n",
       "3          26.50            98.87       567.7            0.2098   \n",
       "4          16.67           152.20      1575.0            0.1374   \n",
       "5          23.75           103.40       741.6            0.1791   \n",
       "6          27.66           153.20      1606.0            0.1442   \n",
       "7          28.14           110.60       897.0            0.1654   \n",
       "8          30.73           106.20       739.3            0.1703   \n",
       "9          40.68            97.65       711.4            0.1853   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "5             0.5249           0.5355                0.1741          0.3985   \n",
       "6             0.2576           0.3784                0.1932          0.3063   \n",
       "7             0.3682           0.2678                0.1556          0.3196   \n",
       "8             0.5401           0.5390                0.2060          0.4378   \n",
       "9             1.0580           1.1050                0.2210          0.4366   \n",
       "\n",
       "   worst fractal dimension  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "5                  0.12440  \n",
       "6                  0.08368  \n",
       "7                  0.11510  \n",
       "8                  0.10720  \n",
       "9                  0.20750  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_data=datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(breast_cancer_data.data,columns=breast_cancer_data.feature_names)\n",
    "df.head(10)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I tried to slice the predictor features. I sliced the radius, texture from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean perimeter  mean area  mean smoothness  mean compactness  \\\n",
       "0          122.80     1001.0          0.11840           0.27760   \n",
       "1          132.90     1326.0          0.08474           0.07864   \n",
       "2          130.00     1203.0          0.10960           0.15990   \n",
       "3           77.58      386.1          0.14250           0.28390   \n",
       "4          135.10     1297.0          0.10030           0.13280   \n",
       "\n",
       "   mean concavity  mean concave points  mean symmetry  mean fractal dimension  \\\n",
       "0          0.3001              0.14710         0.2419                 0.07871   \n",
       "1          0.0869              0.07017         0.1812                 0.05667   \n",
       "2          0.1974              0.12790         0.2069                 0.05999   \n",
       "3          0.2414              0.10520         0.2597                 0.09744   \n",
       "4          0.1980              0.10430         0.1809                 0.05883   \n",
       "\n",
       "   radius error  texture error           ...             worst radius  \\\n",
       "0        1.0950         0.9053           ...                    25.38   \n",
       "1        0.5435         0.7339           ...                    24.99   \n",
       "2        0.7456         0.7869           ...                    23.57   \n",
       "3        0.4956         1.1560           ...                    14.91   \n",
       "4        0.7572         0.7813           ...                    22.54   \n",
       "\n",
       "   worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0          17.33           184.60      2019.0            0.1622   \n",
       "1          23.41           158.80      1956.0            0.1238   \n",
       "2          25.53           152.50      1709.0            0.1444   \n",
       "3          26.50            98.87       567.7            0.2098   \n",
       "4          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst fractal dimension  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.iloc[:,2:32]\n",
    "print(type(X))\n",
    "# displaying the first five rows of X\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying Collinearity\n",
    "\n",
    "To identify the variables with more than 85% correlation we can get the covariance matrix from the code below. Here, 85% is the threshold value chosen by us, it can be any value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xf6ab588>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAikAAAHRCAYAAACvuin3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf69fdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cor=np.corrcoef(X.T)\n",
    "type(cor)\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cor, vmin=0.85,vmax=1,\\\n",
    "            cmap=plt.cm.Spectral_r)\n",
    "#cmap='coolwarm'#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot, we can observe the features that are highly correlated. \n",
    "\n",
    "1. Feature 0,2,3,20,22,23 are highly correlated. Logically, perimeter and area are computed from radius. Therefore, we keep radius and discard perimeter and area.\n",
    "2. Feature 10, 12, 13  are highly correlated to each other so we keep feature 10 and leave the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction using Principle component analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is a technique that extracts valuable set of predictor features/variables by the linear combination of original p predictors in a dataset. These new predictors has the capability of capturing 95% or more of the variance in original data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569L, 10L)\n",
      "[  9.82081720e-01   1.61760674e-02   1.55731872e-03   1.11690228e-04\n",
      "   6.54079071e-05   6.34979544e-06   8.41926150e-07   3.05493182e-07\n",
      "   2.16746194e-07   6.02901200e-08]\n",
      "0.999999978676\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=10)\n",
    "x_pca=pca.fit_transform(X)\n",
    "print (x_pca.shape)\n",
    "print(pca.explained_variance_ratio_) \n",
    "print (pca.explained_variance_ratio_.sum())\n",
    "loadings = pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the first component itself we can say that the result shows more than 95% of the variance in the data. This happens in cases where there is high collinearity. This ultimately influence prediction results if such data is used. Since the PCA is performed on the unscaled data, only one component in the result shows almost all the variance in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### PCA on standardized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the features have very high difference in the variances then the points in the clusters are more likely to be separated.The breast cancer data has different variances which needs to be standardized. Standardscalar here helps in standardizing the data points by removing the mean and scaling each point to unit variance.\n",
    "\n",
    "\n",
    "Standardization centeres the features around a mean of zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569L, 10L)\n",
      "[ 0.44808673  0.1904235   0.10041682  0.05893816  0.04677221  0.04280972\n",
      "  0.02373909  0.01675158  0.01386227  0.01191153]\n",
      "0.953711608295\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pca=PCA(n_components=0.95)\n",
    "x_pca=pca.fit_transform(X_scaled)\n",
    "print (x_pca.shape)\n",
    "print(pca.explained_variance_ratio_) \n",
    "print (pca.explained_variance_ratio_.sum())\n",
    "loadings = pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 10 components explain 95% of the variance in the data compared to just 1 when applying PCA on the unscaled data.\n",
    " \n",
    " From this, we can conclude that PCA with out scaling can hide features with smaller magnitude which are usable to the prediction.\n",
    " \n",
    " We can further see how removing collinear features from the scaled can affect PCA here below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA after removing collinear variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed above while identifying the collinearity, removing area, perimeter,perimeter_worst, area_worst, perimeter_se, area_se  ( columns: 2,3,12,13,22,23,) from the original data using PCA is shown below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569L, 8L)\n",
      "[ 0.47586429  0.19150542  0.09617026  0.06325991  0.05706094  0.032917\n",
      "  0.01904595  0.01631457]\n",
      "0.952138342211\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_scaled=pd.DataFrame(X_scaled)\n",
    "xx=X_scaled.drop(X_scaled.columns[[2, 3, 22, 23, 12, 13]], axis=1) \n",
    "pca=PCA(n_components=0.95)\n",
    "x_pca=pca.fit_transform(xx)\n",
    "print (x_pca.shape)\n",
    "print(pca.explained_variance_ratio_) \n",
    "print (pca.explained_variance_ratio_.sum())\n",
    "loadings = pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xff591d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABH8AAAEICAYAAADGNFhcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY+OG2D+kRskAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xfbb6630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n=['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10']\n",
    "index = np.arange (10)\n",
    "\n",
    "var_1=np.array([9.82044672e-01,1.61764899e-02,1.55751075e-03,1.20931964e-04,8.82724536e-05,6.64883951e-06,4.01713682e-06,8.22017197e-07,3.44135279e-07,1.86018721e-07])                \n",
    "var_sc=np.array([0.44272026,0.18971182,0.09393163,0.06602135,0.05495768,0.04024522,0.02250734,0.01588724,0.01389649,0.01168978])\n",
    "var_sc_coll=np.array([0.42661046,0.15932139,0.10294428,0.07788731,0.06489774,0.05015242,0.02145044,0.0187846,0.01505759,0.01197751])\n",
    "var=np.vstack([var_1,var_sc,var_sc_coll]).T\n",
    "\n",
    "# creating pandas datframe from numpy array 'var'\n",
    "df=pd.DataFrame(var,index=n,columns=['original','scaled','scaled_no_colli'])\n",
    "\n",
    "# plotting variance data \n",
    "%matplotlib inline\n",
    "fig, ax= plt.subplots(1,3,sharey=True,figsize=(20,4))\n",
    "r1 = ax[0].bar(index,df['original'],width = 0.6,align='center')\n",
    "ax[0].set_title('PCA on raw data',fontsize=14)\n",
    "\n",
    "r2 = ax[1].bar(index,df['scaled'],width = 0.6,align='center')\n",
    "ax[1].set_title('PCA on scaled data',fontsize=14)\n",
    "\n",
    "r3 = ax[2].bar(index,df['scaled_no_colli'],width= 0.6,align='center')\n",
    "#ax[2].set_xticklabels(n)\n",
    "ax[2].set_title('PCA after removing collinearity',fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plots we can observe that, stanrdizing the data and using PCA on the scaaled data has improved quite well in capturing variance of the raw data.\n",
    "\n",
    "Removing collinear features allowed the variance from other variables which were previously ignored to be captured by PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibiography\n",
    "\n",
    "\"Dimensionality reduction.\" Wikipedia. December 06, 2017. Accessed December 10, 2017. https://en.wikipedia.org/wiki/Dimensionality_reduction. \n",
    "\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2015/07/dimension-reduction-methods/\n",
    "\n",
    "http://www.statsblogs.com/2013/11/09/multicollinearity-and-collinearity-in-multiple-regression-a-tutorial/\n",
    "\n",
    "https://shiring.github.io/machine_learning/2017/01/15/rfe_ga_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
